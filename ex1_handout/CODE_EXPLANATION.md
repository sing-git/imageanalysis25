# ğŸ” PCA + Vector Quantization ì½”ë“œ ìƒì„¸ ì„¤ëª…

## ğŸ“¦ Import & Class Definition

```python
import numpy as np
```
**ì™œ?** NumPyëŠ” í–‰ë ¬ ì—°ì‚°, SVD, í†µê³„ í•¨ìˆ˜ë¥¼ ì œê³µ. ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ë¶ˆê°€ ì œì•½ ë•Œë¬¸ì— NumPyë§Œ ì‚¬ìš©.

```python
class ImageCompressor:
```
**ì™œ?** í´ë¼ì´ì–¸íŠ¸ ì¸¡ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì••ì¶•í•˜ëŠ” ì—­í• . í•™ìŠµ(train)ê³¼ ì••ì¶•(compress) ê¸°ëŠ¥ ë¶„ë¦¬.

---

## ğŸ¯ `__init__`: ì´ˆê¸°í™”

```python
def __init__(self, n_components=50, n_clusters=64, use_vector_quantization=True, max_kmeans_iters=50):
```
**ì™œ?** 
- `n_components=50`: PCAë¡œ 27,648ì°¨ì›ì„ 50ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ (ê¸°ë³¸ê°’)
- `n_clusters=64`: K-meansë¡œ 50ì°¨ì› ë²¡í„°ë¥¼ 64ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ì••ì¶•
- `use_vector_quantization=True`: VQ ì‚¬ìš© ì—¬ë¶€ (ì‹¤í—˜ìš© í”Œë˜ê·¸)
- `max_kmeans_iters=50`: K-meansê°€ ë„ˆë¬´ ì˜¤ë˜ ëŒì§€ ì•Šë„ë¡ ì œí•œ

```python
self.n_components = n_components
self.n_clusters = n_clusters
self.use_vector_quantization = use_vector_quantization
self.max_kmeans_iters = max_kmeans_iters
```
**ì™œ?** íŒŒë¼ë¯¸í„°ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥í•´ì„œ ë‚˜ì¤‘ì— train(), compress()ì—ì„œ ì‚¬ìš©.

```python
self.mean_image = None
self.components = None
self.explained_variance = None
```
**ì™œ?** PCA í•™ìŠµ ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜ë“¤. ì´ˆê¸°ê°’ì€ None (ì•„ì§ í•™ìŠµ ì•ˆ í•¨).
- `mean_image`: ëª¨ë“  í•™ìŠµ ì´ë¯¸ì§€ì˜ í‰ê·  (27,648 ë²¡í„°)
- `components`: PCA ì£¼ì„±ë¶„ë“¤ (n_components Ã— 27,648 í–‰ë ¬)
- `explained_variance`: ê° ì£¼ì„±ë¶„ì´ ì„¤ëª…í•˜ëŠ” ë¶„ì‚° ë¹„ìœ¨

```python
self.vq_centroids = None
```
**ì™œ?** Vector Quantization í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì ë“¤ ì €ì¥ (n_clusters Ã— n_components í–‰ë ¬).

---

## ğŸ”„ `_kmeans`: K-means í´ëŸ¬ìŠ¤í„°ë§ (NumPy êµ¬í˜„)

```python
def _kmeans(self, X, k, max_iters=50):
```
**ì™œ?** sklearn ì‚¬ìš© ë¶ˆê°€ â†’ NumPyë¡œ K-means ì§ì ‘ êµ¬í˜„. `_`ëŠ” private ë©”ì„œë“œ ì˜ë¯¸.

```python
N, d = X.shape
```
**ì™œ?** N = ë°ì´í„° ê°œìˆ˜, d = ì°¨ì› (ì˜ˆ: 100ê°œ ì´ë¯¸ì§€, 50ì°¨ì›).

```python
np.random.seed(42)
init_indices = np.random.choice(N, k, replace=False)
centroids = X[init_indices].copy()
```
**ì™œ?** 
- `seed(42)`: ì¬í˜„ ê°€ëŠ¥í•œ ëœë¤ (ë””ë²„ê¹… ìš©ì´)
- `np.random.choice(N, k, replace=False)`: Nê°œ ì¤‘ kê°œ ëœë¤ ì„ íƒ (ì¤‘ë³µ X)
- ì´ˆê¸° ì¤‘ì‹¬ì ì„ ëœë¤í•˜ê²Œ ì„ íƒ (K-means í‘œì¤€ ë°©ë²•)

```python
for iteration in range(max_iters):
```
**ì™œ?** K-meansëŠ” ë°˜ë³µ ì•Œê³ ë¦¬ì¦˜. ìµœëŒ€ 50ë²ˆ ë°˜ë³µ.

```python
distances = np.zeros((N, k))
for i in range(k):
    diff = X - centroids[i]
    distances[:, i] = np.sum(diff ** 2, axis=1)
```
**ì™œ?** 
- ê° ë°ì´í„°ì™€ ëª¨ë“  ì¤‘ì‹¬ì  ê°„ì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬^2 ê³„ì‚°
- `X - centroids[i]`: Broadcastingìœ¼ë¡œ (N, d) - (d,) = (N, d)
- `np.sum(..., axis=1)`: ê° í–‰(ë°ì´í„°)ë§ˆë‹¤ ê±°ë¦¬ í•©ì‚° â†’ (N,)
- ê²°ê³¼: `distances[j, i]` = jë²ˆì§¸ ë°ì´í„°ì™€ ië²ˆì§¸ ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬

```python
labels = np.argmin(distances, axis=1)
```
**ì™œ?** ê° ë°ì´í„°ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ì¤‘ì‹¬ì ì— í• ë‹¹. `labels[j]` = jë²ˆì§¸ ë°ì´í„°ê°€ ì†í•œ í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸.

```python
new_centroids = np.zeros_like(centroids)
for i in range(k):
    cluster_points = X[labels == i]
    if len(cluster_points) > 0:
        new_centroids[i] = np.mean(cluster_points, axis=0)
    else:
        new_centroids[i] = centroids[i]
```
**ì™œ?** 
- ê° í´ëŸ¬ìŠ¤í„°ì— ì†í•œ ë°ì´í„°ë“¤ì˜ í‰ê· ìœ¼ë¡œ ì¤‘ì‹¬ì  ì—…ë°ì´íŠ¸
- `X[labels == i]`: ië²ˆ í´ëŸ¬ìŠ¤í„°ì— ì†í•œ ëª¨ë“  ë°ì´í„°
- `if len(cluster_points) > 0`: ë¹ˆ í´ëŸ¬ìŠ¤í„° ë°©ì§€ (ìˆìœ¼ë©´ ê¸°ì¡´ ì¤‘ì‹¬ì  ìœ ì§€)

```python
centroid_shift = np.sum((new_centroids - centroids) ** 2)
centroids = new_centroids
```
**ì™œ?** 
- ì¤‘ì‹¬ì ì´ ì–¼ë§ˆë‚˜ ì›€ì§ì˜€ëŠ”ì§€ ì¸¡ì • (ìˆ˜ë ´ ì²´í¬ìš©)
- ì¤‘ì‹¬ì  ì—…ë°ì´íŠ¸

```python
if centroid_shift < 1e-6:
    print(f"    Converged at iteration {iteration}")
    break
```
**ì™œ?** ì¤‘ì‹¬ì ì´ ê±°ì˜ ì•ˆ ì›€ì§ì´ë©´ ìˆ˜ë ´í•œ ê²ƒ â†’ ì¡°ê¸° ì¢…ë£Œ (ì‹œê°„ ì ˆì•½).

---

## ğŸ“š `get_codebook`: ì½”ë“œë¶ ìƒì„±

```python
if self.mean_image is None or self.components is None:
    return np.array([])
```
**ì™œ?** í•™ìŠµ ì•ˆ í–ˆìœ¼ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜ (ì—ëŸ¬ ë°©ì§€).

```python
if self.use_vector_quantization:
```
**ì™œ?** VQ ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ì½”ë“œë¶ êµ¬ì¡°ê°€ ë‹¤ë¦„.

```python
metadata = np.array([
    self.n_components,
    self.n_clusters
], dtype=np.float32)
```
**ì™œ?** 
- ë³µì› ì‹œ íŒŒì‹±í•˜ê¸° ìœ„í•´ íŒŒë¼ë¯¸í„° ì •ë³´ ì €ì¥
- ì½”ë“œë¶ ì•ë¶€ë¶„ì— ë©”íƒ€ë°ì´í„° ì‚½ì…

```python
codebook = np.concatenate([
    metadata,
    self.mean_image.flatten(),
    self.components.flatten(),
    self.vq_centroids.flatten()
])
```
**ì™œ?** 
- ëª¨ë“  ì •ë³´ë¥¼ 1ì°¨ì› ë°°ì—´ë¡œ í•©ì¹¨
- **êµ¬ì¡°**: [n_components, n_clusters] + [í‰ê·  ì´ë¯¸ì§€ 27,648] + [ì£¼ì„±ë¶„ n_componentsÃ—27,648] + [VQ ì¤‘ì‹¬ì  n_clustersÃ—n_components]
- ì˜ˆ: [50, 64] + [27,648] + [50Ã—27,648] + [64Ã—50] = ì´ 1,384,402ê°œ ê°’

```python
return codebook.astype(np.float16)
```
**ì™œ?** 
- float32 â†’ float16: ë©”ëª¨ë¦¬ ì ˆë°˜ìœ¼ë¡œ ì ˆì•½ (ì •í™•ë„ ì•½ê°„ ì†ì‹¤, ì••ì¶•ì—ì„  OK)
- ì½”ë“œë¶ í¬ê¸°: ~2.6MB (float16) vs ~5.2MB (float32)

---

## ğŸ“ `train`: PCA + VQ í•™ìŠµ

### STEP 1: PCA í•™ìŠµ

```python
image_vectors = []
for img in train_images:
    img_vector = img.astype(np.float32).flatten()
    image_vectors.append(img_vector)
```
**ì™œ?** 
- ê° ì´ë¯¸ì§€ (96Ã—96Ã—3) â†’ 1ì°¨ì› ë²¡í„° (27,648)
- `astype(np.float32)`: uint8 (0-255) â†’ float32 (PCAëŠ” ì‹¤ìˆ˜ ì—°ì‚° í•„ìš”)

```python
X = np.array(image_vectors)  # (N, 27648)
```
**ì™œ?** ë¦¬ìŠ¤íŠ¸ â†’ NumPy ë°°ì—´ë¡œ ë³€í™˜. í–‰ë ¬ ì—°ì‚° ê°€ëŠ¥.

```python
self.mean_image = np.mean(X, axis=0)
X_centered = X - self.mean_image
```
**ì™œ?** 
- PCAëŠ” ë°ì´í„°ë¥¼ ì¤‘ì‹¬í™”(í‰ê· =0)í•´ì•¼ í•¨ (ì´ë¡ ì  ìš”êµ¬ì‚¬í•­)
- `axis=0`: ê° ì—´(í”½ì…€)ì˜ í‰ê·  ê³„ì‚° â†’ (27,648,)
- `X - self.mean_image`: Broadcastingìœ¼ë¡œ ê° ì´ë¯¸ì§€ì—ì„œ í‰ê·  ë¹¼ê¸°

```python
U, S, Vt = np.linalg.svd(X_centered, full_matrices=False)
```
**ì™œ?** 
- **SVD (Singular Value Decomposition)**: X = U Ã— S Ã— Vt
- PCAëŠ” SVDì˜ íŠ¹ìˆ˜ ì¼€ì´ìŠ¤
- `full_matrices=False`: ë©”ëª¨ë¦¬ ì ˆì•½ (ì‘ì€ í–‰ë ¬ë§Œ ë°˜í™˜)
- **ê²°ê³¼**:
  - `U`: (N, N) ë˜ëŠ” (N, min(N, d))
  - `S`: (min(N, d),) - íŠ¹ì´ê°’ë“¤ (ì¤‘ìš”ë„ ìˆœì„œ)
  - `Vt`: (min(N, d), d) - **ì£¼ì„±ë¶„ ë²¡í„°ë“¤** (ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²ƒ!)

```python
explained_variance_ratio = (S ** 2) / np.sum(S ** 2)
cumsum_variance = np.cumsum(explained_variance_ratio)
```
**ì™œ?** 
- ê° ì£¼ì„±ë¶„ì´ ì„¤ëª…í•˜ëŠ” ë¶„ì‚° ë¹„ìœ¨ ê³„ì‚° (ì¤‘ìš”ë„ ì¸¡ì •)
- `S ** 2`: íŠ¹ì´ê°’ â†’ ë¶„ì‚°ìœ¼ë¡œ ë³€í™˜
- `cumsum`: ëˆ„ì  í•© (ì˜ˆ: ì²« 50ê°œ ì£¼ì„±ë¶„ì´ ì „ì²´ ë¶„ì‚°ì˜ 95% ì„¤ëª…)

```python
if self.n_components > len(S):
    self.n_components = len(S)
```
**ì™œ?** ì£¼ì„±ë¶„ ê°œìˆ˜ê°€ ë°ì´í„°ë³´ë‹¤ ë§ìœ¼ë©´ ì¡°ì • (ì—ëŸ¬ ë°©ì§€).

```python
self.components = Vt[:self.n_components]  # (n_components, 27648)
```
**ì™œ?** ìƒìœ„ n_componentsê°œ ì£¼ì„±ë¶„ë§Œ ì„ íƒ (ì°¨ì› ì¶•ì†Œ).

### STEP 2: Vector Quantization í•™ìŠµ

```python
pca_coefficients = []
for img_vector in image_vectors:
    img_centered = img_vector - self.mean_image
    coeffs = np.dot(self.components, img_centered)
    pca_coefficients.append(coeffs)
```
**ì™œ?** 
- ê° í•™ìŠµ ì´ë¯¸ì§€ë¥¼ PCA ê³µê°„ìœ¼ë¡œ ë³€í™˜
- `np.dot(self.components, img_centered)`: (n_components, 27648) Ã— (27648,) = (n_components,)
- 27,648ì°¨ì› â†’ n_componentsì°¨ì› (ì˜ˆ: 50ì°¨ì›)

```python
pca_coeffs_matrix = np.array(pca_coefficients)  # (N, n_components)
```
**ì™œ?** ë¦¬ìŠ¤íŠ¸ â†’ í–‰ë ¬ ë³€í™˜. K-means ì…ë ¥ìš©.

```python
self.vq_centroids = self._kmeans(
    pca_coeffs_matrix, 
    self.n_clusters, 
    max_iters=self.max_kmeans_iters
)
```
**ì™œ?** 
- PCA ê³„ìˆ˜ë“¤ì„ n_clustersê°œë¡œ í´ëŸ¬ìŠ¤í„°ë§
- **í•µì‹¬ ì•„ì´ë””ì–´**: ë¹„ìŠ·í•œ PCA ê³„ìˆ˜ë¥¼ ê°€ì§„ ì´ë¯¸ì§€ë“¤ì„ ê°™ì€ í´ëŸ¬ìŠ¤í„°ë¡œ ë¬¶ê¸°
- ì••ì¶• ì‹œ í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ë§Œ ì €ì¥ (1 byte)

---

## ğŸ—œï¸ `compress`: ì´ë¯¸ì§€ ì••ì¶•

```python
if self.mean_image is None or self.components is None:
    raise ValueError("Model has not been trained yet!")
```
**ì™œ?** í•™ìŠµ ì•ˆ í–ˆìœ¼ë©´ ì—ëŸ¬ ë°œìƒ (ì•ˆì „ì¥ì¹˜).

```python
img_vector = test_image.astype(np.float32).flatten()
img_centered = img_vector - self.mean_image
```
**ì™œ?** 
- ì´ë¯¸ì§€ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
- í•™ìŠµ ë•Œì™€ ë™ì¼í•˜ê²Œ ì¤‘ì‹¬í™” (í‰ê·  ë¹¼ê¸°)

```python
pca_coefficients = np.dot(self.components, img_centered)
```
**ì™œ?** 
- PCA ë³€í™˜: 27,648ì°¨ì› â†’ n_componentsì°¨ì›
- ì´ê²Œ ê¸°ë³¸ ì••ì¶• ê²°ê³¼ (VQ ì•ˆ ì“°ë©´ ì´ê±¸ ë°˜í™˜)

```python
distances = np.zeros(self.n_clusters)
for i in range(self.n_clusters):
    diff = pca_coefficients - self.vq_centroids[i]
    distances[i] = np.sum(diff ** 2)
```
**ì™œ?** 
- í˜„ì¬ PCA ê³„ìˆ˜ì™€ ëª¨ë“  í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬ ê³„ì‚°
- ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„° ì°¾ê¸° ìœ„í•¨

```python
cluster_idx = np.argmin(distances)
```
**ì™œ?** ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„°ì˜ ì¸ë±ìŠ¤ ì°¾ê¸°.

```python
if self.n_clusters <= 256:
    return np.array([cluster_idx], dtype=np.uint8)
else:
    return np.array([cluster_idx], dtype=np.uint16)
```
**ì™œ?** 
- **ì••ì¶• í•µì‹¬!** 27,648 bytes â†’ **1 byte** (ë˜ëŠ” 2 bytes)
- 256ê°œ ì´í•˜: uint8 (0-255, 1 byte)
- 257ê°œ ì´ìƒ: uint16 (0-65535, 2 bytes)

---

## ğŸ”§ `ImageReconstructor`: ì´ë¯¸ì§€ ë³µì›

### `__init__`

```python
self.codebook = codebook
if len(codebook) > 0:
    self._parse_codebook()
```
**ì™œ?** ì½”ë“œë¶ ë°›ì•„ì„œ ë°”ë¡œ íŒŒì‹± (ì„œë²„ ì¸¡ì—ì„œ ì‚¬ìš©).

### `_parse_codebook`

```python
img_size = 96 * 96 * 3  # 27648
```
**ì™œ?** ì´ë¯¸ì§€ í¬ê¸° ìƒìˆ˜ (ì½”ë“œë¶ íŒŒì‹± ì‹œ ì‚¬ìš©).

```python
if len(self.codebook) > img_size + 2:
    # VQ ëª¨ë“œ
```
**ì™œ?** 
- ì½”ë“œë¶ í¬ê¸°ë¡œ VQ ì‚¬ìš© ì—¬ë¶€ íŒë‹¨
- VQ ëª¨ë“œ: metadata(2) + mean(27,648) + components + centroids
- PCA ëª¨ë“œ: mean(27,648) + components

```python
self.n_components = int(self.codebook[0])
self.n_clusters = int(self.codebook[1])
```
**ì™œ?** ë©”íƒ€ë°ì´í„°ì—ì„œ íŒŒë¼ë¯¸í„° ë³µì›.

```python
start_idx = 2
end_idx = start_idx + img_size
self.mean_image = self.codebook[start_idx:end_idx]
```
**ì™œ?** 
- ì¸ë±ìŠ¤ 2~27,649: í‰ê·  ì´ë¯¸ì§€
- ìŠ¬ë¼ì´ì‹±ìœ¼ë¡œ ì¶”ì¶œ

```python
start_idx = end_idx
end_idx = start_idx + (self.n_components * img_size)
components_flat = self.codebook[start_idx:end_idx]
self.components = components_flat.reshape(self.n_components, img_size)
```
**ì™œ?** 
- ë‹¤ìŒ n_components Ã— 27,648ê°œ ê°’: ì£¼ì„±ë¶„ë“¤
- 1ì°¨ì› â†’ 2ì°¨ì› í–‰ë ¬ë¡œ reshape

```python
start_idx = end_idx
vq_flat = self.codebook[start_idx:]
self.vq_centroids = vq_flat.reshape(self.n_clusters, self.n_components)
```
**ì™œ?** 
- ë‚˜ë¨¸ì§€: VQ ì¤‘ì‹¬ì ë“¤
- (n_clusters, n_components) í–‰ë ¬ë¡œ reshape

### `reconstruct`

```python
if self.use_vq:
    cluster_idx = int(test_code[0])
    pca_coefficients = self.vq_centroids[cluster_idx]
else:
    pca_coefficients = test_code
```
**ì™œ?** 
- VQ ëª¨ë“œ: í´ëŸ¬ìŠ¤í„° ì¸ë±ìŠ¤ â†’ í•´ë‹¹ ì¤‘ì‹¬ì (PCA ê³„ìˆ˜) ê°€ì ¸ì˜¤ê¸°
- PCA ëª¨ë“œ: ê³„ìˆ˜ ì§ì ‘ ì‚¬ìš©

```python
reconstructed_vector = self.mean_image.copy()
for i, coeff in enumerate(pca_coefficients):
    reconstructed_vector += coeff * self.components[i]
```
**ì™œ?** 
- **PCA ì—­ë³€í™˜ ê³µì‹**: ì´ë¯¸ì§€ = í‰ê·  + Î£(ê³„ìˆ˜_i Ã— ì£¼ì„±ë¶„_i)
- ê° ì£¼ì„±ë¶„ì— ê³„ìˆ˜ ê³±í•´ì„œ í•©ì‚°

```python
reconstructed_image = reconstructed_vector.reshape(96, 96, 3)
```
**ì™œ?** 1ì°¨ì› ë²¡í„° â†’ 3ì°¨ì› ì´ë¯¸ì§€ë¡œ ë³€í™˜.

```python
reconstructed_image = np.clip(reconstructed_image, 0, 255)
```
**ì™œ?** 
- PCA ì—­ë³€í™˜ ê²°ê³¼ê°€ [0, 255] ë²”ìœ„ ë²—ì–´ë‚  ìˆ˜ ìˆìŒ
- ìŒìˆ˜ë‚˜ 255 ì´ˆê³¼ ê°’ì„ 0ê³¼ 255ë¡œ ì œí•œ

```python
reconstructed_image = self._quantize_colors(reconstructed_image)
```
**ì™œ?** í‹±íƒí†  íŠ¹ì„± ë°˜ì˜: 4ê°€ì§€ ìƒ‰ìƒìœ¼ë¡œ ì–‘ìí™”.

### `_quantize_colors`

```python
colors = np.array([
    [255, 255, 255],  # í°ìƒ‰ (ë°°ê²½)
    [0, 0, 0],        # ê²€ì€ìƒ‰ (ê²©ì)
    [255, 0, 0],      # ë¹¨ê°„ìƒ‰ (X)
    [0, 255, 0]       # ë…¹ìƒ‰ (O)
])
```
**ì™œ?** í‹±íƒí† ëŠ” 4ê°€ì§€ ìƒ‰ìƒë§Œ ì‚¬ìš© â†’ ëŒ€í‘œ ìƒ‰ìƒ ì •ì˜.

```python
distances = np.sum((colors - pixel) ** 2, axis=1)
closest_color_idx = np.argmin(distances)
quantized[i, j] = colors[closest_color_idx]
```
**ì™œ?** 
- ê° í”½ì…€ì„ ê°€ì¥ ê°€ê¹Œìš´ ëŒ€í‘œ ìƒ‰ìƒìœ¼ë¡œ ë§¤í•‘
- ìœ í´ë¦¬ë“œ ê±°ë¦¬ ì‚¬ìš© (RGB ê³µê°„)

---

## ğŸ¯ ì „ì²´ íë¦„ ìš”ì•½

### í•™ìŠµ ë‹¨ê³„:
1. **ì´ë¯¸ì§€ â†’ ë²¡í„°** (96Ã—96Ã—3 â†’ 27,648)
2. **PCA**: 27,648ì°¨ì› â†’ 50ì°¨ì›
3. **K-means**: 50ì°¨ì› ë²¡í„°ë“¤ì„ 64ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ê·¸ë£¹í™”
4. **ì½”ë“œë¶ ìƒì„±**: í‰ê·  + ì£¼ì„±ë¶„ + í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì  ì €ì¥

### ì••ì¶• ë‹¨ê³„:
1. **ì´ë¯¸ì§€ â†’ ë²¡í„°** (27,648)
2. **PCA ë³€í™˜** (27,648 â†’ 50ì°¨ì›)
3. **ê°€ì¥ ê°€ê¹Œìš´ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°**
4. **í´ëŸ¬ìŠ¤í„° ì¸ë±ìŠ¤ ì €ì¥** (1 byte!)

### ë³µì› ë‹¨ê³„:
1. **í´ëŸ¬ìŠ¤í„° ì¸ë±ìŠ¤ â†’ PCA ê³„ìˆ˜** (1 byte â†’ 50ê°œ float)
2. **PCA ì—­ë³€í™˜** (50ì°¨ì› â†’ 27,648ì°¨ì›)
3. **ë²¡í„° â†’ ì´ë¯¸ì§€** (27,648 â†’ 96Ã—96Ã—3)
4. **4ìƒ‰ ì–‘ìí™”** (í‹±íƒí†  íŠ¹ì„±)

---

## ğŸ’¡ í•µì‹¬ ì•„ì´ë””ì–´

**ì™œ PCA + VQê°€ íš¨ê³¼ì ì¸ê°€?**

1. **PCA**: 27,648ì°¨ì›ì€ ë„ˆë¬´ í¬ë‹¤ â†’ 50ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ (99% ì •ë³´ ìœ ì§€)
2. **VQ**: 50ê°œ float(100 bytes) ì €ì¥ë„ í¬ë‹¤ â†’ í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸(1 byte)ë¡œ ëŒ€ì²´
3. **ì••ì¶• ë¹„ìœ¨**: 27,648 bytes â†’ **1 byte** (27,648:1!)

**íŠ¸ë ˆì´ë“œì˜¤í”„**:
- ì••ì¶•ë¥  â†‘ (1 byte ë§¤ìš° ì‘ìŒ)
- í’ˆì§ˆ â†“ (ë¹„ìŠ·í•œ ì´ë¯¸ì§€ë“¤ì´ ê°™ì€ í´ëŸ¬ìŠ¤í„°ë¡œ ë¬¶ì„ â†’ ì„¸ë¶€ì‚¬í•­ ì†ì‹¤)
